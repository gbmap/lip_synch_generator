{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allosaurus.app import read_recognizer\n",
    "model = read_recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " 'a',\n",
       " 'ɐ',\n",
       " 'ɑ',\n",
       " 'ɒ',\n",
       " 'æ',\n",
       " 'ɶ',\n",
       " 'ɛ',\n",
       " 'œ',\n",
       " 'ɜ',\n",
       " 'ɞ',\n",
       " 'ʌ',\n",
       " 'e',\n",
       " 'ɘ',\n",
       " 't͡ʃʲ',\n",
       " 'o',\n",
       " 'ɔ',\n",
       " 'ø',\n",
       " 'ɤ',\n",
       " 'uə',\n",
       " 'ʂ',\n",
       " 's',\n",
       " 'ŋ',\n",
       " 'l',\n",
       " 'm',\n",
       " 'b',\n",
       " 'p',\n",
       " 'q',\n",
       " 'w',\n",
       " 'u',\n",
       " 'ɯ',\n",
       " 'ʊ',\n",
       " 'ʉ',\n",
       " 'ɻ̩',\n",
       " 't͡',\n",
       " 'r',\n",
       " 'ʃ',\n",
       " 'i',\n",
       " 'ɪ',\n",
       " 'ɨ',\n",
       " 'ʏ',\n",
       " 'ᵻ',\n",
       " 'y',\n",
       " 'ɨ']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from PIL import Image\n",
    "\n",
    "class Frames:\n",
    "    def __init__(self, config_file: str):\n",
    "        self.folder = os.path.dirname(config_file)\n",
    "        self.data = yaml.load(open(config_file,'r',encoding='utf8'), yaml.FullLoader)\n",
    "        self.image_cache = {}\n",
    "    \n",
    "    def get_image_filename(self, phoneme: str) -> str:\n",
    "        for image_data in self.data['images']:\n",
    "            if phoneme in image_data['symbols']:\n",
    "                return self.folder + os.path.sep + image_data['image']\n",
    "        return None\n",
    "\n",
    "    def get_image(self, phoneme: str) -> Image.Image:\n",
    "        filename = self.get_image_filename(phoneme)\n",
    "        if filename is None:\n",
    "            return None\n",
    "\n",
    "        if filename in self.image_cache:\n",
    "            return self.image_cache[filename]\n",
    "        else:\n",
    "            image = Image.open(filename)\n",
    "            self.image_cache[filename] = image\n",
    "            return image\n",
    "    \n",
    "    def get_symbols(self):\n",
    "        for image_data in self.data['images']:\n",
    "            for symbol in image_data['symbols']:\n",
    "                yield symbol\n",
    "\n",
    "    def has_phoneme_image(self, phoneme: str):\n",
    "        for image_data in self.data['images']:\n",
    "            if phoneme in image_data['symbols']:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "frames = Frames('test_config/config.yml')\n",
    "list(frames.get_symbols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phoneme:\n",
    "    start_time: float\n",
    "    duration: float\n",
    "    phoneme: str\n",
    "\n",
    "    def __init__(self, start_time: float, duration: float, phoneme: str):\n",
    "        self.start_time = start_time\n",
    "        self.duration = duration \n",
    "        self.phoneme = phoneme\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Phoneme({self.start_time}, {self.duration}, {self.phoneme})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme(0.06, 0.03, ɳ)\n",
      "Phoneme(0.09, 0.09, ɒ)\n",
      "Phoneme(0.18, 0.09000000000000002, u)\n",
      "Phoneme(0.27, 0.02999999999999997, p)\n",
      "Phoneme(0.3, 0.18, uə)\n",
      "Phoneme(0.48, 0.08999999999999997, ʂ)\n",
      "Phoneme(0.57, 0.2800000000000001, ɻ̩)\n",
      "Phoneme(0.8500000000000001, 0.04999999999999993, -)\n",
      "Phoneme(0.9, 0.05999999999999994, m)\n",
      "Phoneme(0.96, 0.20999999999999996, a)\n",
      "Phoneme(1.17, 0.09000000000000008, s)\n",
      "Phoneme(1.26, 0.030000000000000027, l)\n",
      "Phoneme(1.29, 0.06000000000000005, u)\n",
      "Phoneme(1.35, 0.05999999999999983, ŋ)\n",
      "Phoneme(1.41, 0.09000000000000008, ɡ̤)\n",
      "Phoneme(1.5, 0.2800000000000001, a)\n",
      "Phoneme(1.78, 0.050000000000000044, -)\n",
      "Phoneme(1.83, 0.20999999999999996, ɳ)\n",
      "Phoneme(2.04, 0.08999999999999986, s)\n",
      "Phoneme(2.13, 0.1499999999999999, ɒ)\n",
      "Phoneme(2.28, 0.06000000000000005, ɡ)\n",
      "Phoneme(2.34, 0.18000000000000016, o)\n",
      "Phoneme(2.52, 0.029999999999999805, b̤)\n",
      "Phoneme(2.55, 0.4000000000000002, uə)\n",
      "Phoneme(2.95, 0.04999999999999982, -)\n",
      "Phoneme(3.0, 0.06000000000000005, s)\n",
      "Phoneme(3.06, 0.08999999999999986, i)\n",
      "Phoneme(3.15, 0.06000000000000005, b)\n",
      "Phoneme(3.21, 0.18000000000000016, iː)\n",
      "Phoneme(3.39, 0.24999999999999983, ɳ)\n",
      "Phoneme(3.64, 0.04999999999999982, -)\n",
      "Phoneme(3.69, 0.045, t͡ʃʲ)\n",
      "Phoneme(3.735, 0.1, -)\n"
     ]
    }
   ],
   "source": [
    "result = model.recognize(\"virus_mixagem_3_chunk22.wav\", timestamp=True)\n",
    "silence_duration_threshold = 0.25\n",
    "silence_duration = 0.05\n",
    "phonemes = []\n",
    "for str_phoneme in result.split('\\n'):\n",
    "    values = str_phoneme.split(' ')\n",
    "    phonemes.append(Phoneme(float(values[0]), float(values[1]), values[2]))\n",
    "\n",
    "for i, phoneme in enumerate(phonemes):\n",
    "    if i == len(phonemes)-1:\n",
    "        duration = phoneme.duration\n",
    "    else:\n",
    "        duration = phonemes[i+1].start_time - phoneme.start_time\n",
    "    phoneme.duration = duration\n",
    "    if duration > silence_duration_threshold and phonemes[i-1].phoneme != '-':\n",
    "        phoneme.duration -= silence_duration\n",
    "        phonemes.insert(i+1, Phoneme(phoneme.start_time + phoneme.duration, silence_duration, \"-\"))\n",
    "\n",
    "# Add silence to end.\n",
    "phonemes.append(Phoneme(phonemes[-1].start_time + phonemes[-1].duration, 0.1, \"-\"))\n",
    "\n",
    "for phoneme in phonemes:\n",
    "    print(phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " 'ɒ',\n",
       " 'u',\n",
       " 'p',\n",
       " 'uə',\n",
       " 'ʂ',\n",
       " 'ɻ̩',\n",
       " '-',\n",
       " 'm',\n",
       " 'a',\n",
       " 's',\n",
       " 'l',\n",
       " 'u',\n",
       " 'ŋ',\n",
       " 'ŋ',\n",
       " 'a',\n",
       " '-',\n",
       " '-',\n",
       " 's',\n",
       " 'ɒ',\n",
       " 'ɒ',\n",
       " 'o',\n",
       " 'o',\n",
       " 'uə',\n",
       " '-',\n",
       " 's',\n",
       " 'i',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " '-',\n",
       " 't͡ʃʲ',\n",
       " '-']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_symbols = list(frames.get_symbols())\n",
    "def update_phoneme_list(phonemes):\n",
    "    last_available_phoneme = available_symbols[0]\n",
    "    for phoneme in phonemes:\n",
    "        if phoneme.phoneme in available_symbols:\n",
    "            last_available_phoneme = phoneme.phoneme\n",
    "        else:\n",
    "            phoneme.phoneme = last_available_phoneme\n",
    "\n",
    "updated_phonemes = phonemes.copy()\n",
    "update_phoneme_list(updated_phonemes)\n",
    "[phoneme.phoneme for phoneme in updated_phonemes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (266652320.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [15]\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://media1.thehungryjpeg.com/thumbs2/ori_3489187_fa8c67ce7d99079b813850ea43a09a7adb42c3ec_expressive-cartoon-articulation-mouth-lips-lip-sync-animation-phonem.jpg\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://media1.thehungryjpeg.com/thumbs2/ori_3489187_fa8c67ce7d99079b813850ea43a09a7adb42c3ec_expressive-cartoon-articulation-mouth-lips-lip-sync-animation-phonem.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
    "\n",
    "def add_phoneme_with_duration_to_video(clips, phoneme, duration):\n",
    "    clip = ImageClip(frames.get_image_filename(phoneme), transparent=True, duration=duration)\n",
    "    clips.append(clip)\n",
    "\n",
    "\n",
    "def generate_video(phonemes):\n",
    "    clips = []\n",
    "    duration = 0.0\n",
    "    for i, phoneme in enumerate(phonemes):\n",
    "        if i == len(phonemes)-1:\n",
    "            duration = phoneme.duration\n",
    "        else:\n",
    "            duration = phonemes[i+1].start_time - phoneme.start_time\n",
    "        if frames.has_phoneme_image(phoneme.phoneme):\n",
    "            add_phoneme_with_duration_to_video(clips, phoneme.phoneme, duration)\n",
    "        else:\n",
    "            # No initial image\n",
    "            if i == 0:\n",
    "                add_phoneme_with_duration_to_video(clips, '-', duration)\n",
    "            else:\n",
    "                add_phoneme_with_duration_to_video(clips, phonemes[i].phoneme, duration)\n",
    "    return clips\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test.mp4.\n",
      "MoviePy - Writing audio in testTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video test.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test.mp4\n"
     ]
    }
   ],
   "source": [
    "clips = generate_video(updated_phonemes)\n",
    "video = concatenate_videoclips(clips, method=\"compose\")\n",
    "audio = AudioFileClip(\"virus_mixagem_3_chunk22.wav\")\n",
    "video.audio = audio\n",
    "video.write_videofile(\"test.mp4\", fps=24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d1318f30df7b832f004202aeba035278833e1c0dabfb977fb479eaecfa9ce1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
